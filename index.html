<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Sehyun Kwon</title>
  <meta name="author" content="Sehyun Kwon">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Sehyun Kwon</name>
                  </p>
                  <p>I am a Staff Engineer at <a href="https://research.samsung.com">Samsung Research</a>, where I develop on-device AI models.
                  </p>
                  <p>
                    I did my Ph.D. in Artificial Intelligence at Seoul National University, where I was advised by <a href="https://ernestryu.com/">Ernest K. Ryu</a> and M.S. in the Mathematical Sciences at Seoul National University and B.S. in Mathematics Education at Dankook University.
                  </p>
                  <p>
                    Also, I worked as a research scientist intern at <a href="https://naver-career.gitbook.io/en/teams/clova-cic/ai-lab">NAVER AI Lab</a> and <a href="https://www.krafton.ai/en">KRAFTON AI</a>.
                  </p>
                  <p>
                    Here is my <a href="assets/pdf/20260131_cv.pdf">CV</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:shyun.kwon@samsung.com">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=p9oKN9kAAAAJ">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://twitter.com/sehyunkwon22">X</a> &nbsp/&nbsp
                    <a href="https://github.com/sehyunkwon">Github</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/sehyun-kwon-79175823a">LinkedIn</a>
                  </p>
                </td>
                <td style="padding:5.5%;width:30%;max-width:30%">
                  <a href="assets/img/IMG_2365.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="assets/img/profile.JPG" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    I am interested in Language Models, Multi-modal Learning, Information Retrieval, and Clustering. My research aims for a fundamental understanding of these models to tackle inherent ambiguity. Some papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr bgcolor="#ffffd0">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <img src="assets/img/geometric_collapse.png" alt="Preprint" width="220" style="border-style: none">
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <papertitle>Geometric Collapse in Compositional Dense Retrieval</papertitle>
                  <br>
                  <strong>Sehyun Kwon</strong>, Sahngmin Yoo
                  <br>
                  <em>Preprint</em>, 2026
                  <br>
                  <p></p>
                  <p>Providing theoretical and empirical evidence of the inherent limitations of dense retrieval for handling compositional intents.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <img src="assets/img/task_diversity_main.png" alt="TMLR" width="220" style="border-style: none">
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/forum?id=7t5DzaJOdB">
                    <papertitle>Task Diversity Shortens the In-context Learning Plateau</papertitle>
                  </a>
                  <br>
                  Jaeyeon Kim*, <strong>Sehyun Kwon*</strong>, Joo Young Choi, Jongho Park, Jaewoong Cho, Jason D. Lee, Ernest K. Ryu
                  <br>
                  <em>Transactions on Machine Learning Research (TMLR)</em>, 2025
                  <br>
                  <a href="https://openreview.net/forum?id=7t5DzaJOdB">paper</a>
                  /
                  <a href="https://github.com/sehyunkwon/task-diversity-icl">code</a>
                  <p></p>
                  <p> Revealing that training on multiple diverse In-context Learning tasks simultaneously shortens the loss plateaus, making each task easier to learn.</p>
                </td>
              </tr>

              <tr bgcolor="#ffffd0">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <img src="assets/img/ictc.jpg" alt="ICLR" width="220" style="border-style: none">
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/forum?id=G2cG3mQqop">
                    <papertitle>Image Clustering Conditioned on Text Criteria</papertitle>
                  </a>
                  <br>
                  <strong>Sehyun Kwon</strong>, Jaeseung Park, Minkyu Kim, Jaewoong Cho, Ernest K. Ryu, Kangwook Lee
                  <br>
                  <em>International Conference on Learning Representations (ICLR)</em>, 2024
                  <br>
                  <a href="https://openreview.net/forum?id=G2cG3mQqop">paper</a>
                  /
                  <a href="https://github.com/sehyunkwon/ICTC">code</a>
                  /
                  <a href="https://x.com/Kangwook_Lee/status/1719858539416408357?s=20">summary1</a>
                  /
                  <a href="https://x.com/ErnestRyu/status/1719759332584329405?s=20">summary2</a>
                  <p></p>
                  <p>Prosposing the first framework to resolve the fundamental ambiguity of clustering by explicitly conditioning the process on user-provided text criteria.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <img src="assets/img/irl-inr.png" alt="ICML" width="220" style="border-style: none">
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://proceedings.mlr.press/v202/kwon23a.html">
                    <papertitle>Rotation and Translation Invariant Representation Learning with Implicit Neural Representations</papertitle>
                  </a>
                  <br>
                  <strong>Sehyun Kwon</strong>, Joo Young Choi, Ernest K. Ryu
                  <br>
                  <em>International Conference on Machine Learning (ICML)</em>, 2023
                  <br>
                  <a href="https://proceedings.mlr.press/v202/kwon23a.html">paper</a>
                  /
                  <a href="https://github.com/sehyunkwon/IRL-INR">code</a>
                  <p></p>
                  <p>We develop invariant representation learning methods using implicit neural representations for geometric transformations.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <img src="assets/img/wgan.png" alt="ICML" width="220" style="border-style: none">
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://proceedings.mlr.press/v139/no21a.html">
                    <papertitle>WGAN with an Infinitely Wide Generator Has No Spurious Stationary Points</papertitle>
                  </a>
                  <br>
                  Albert No, TaeHo Yoon, <strong>Sehyun Kwon</strong>, Ernest K. Ryu
                  <br>
                  <em>International Conference on Machine Learning (ICML)</em>, 2021
                  <br>
                  <a href="https://proceedings.mlr.press/v139/no21a.html">paper</a>
                  /
                  <a href="https://github.com/sehyunkwon/Infinite-WGAN">code</a>
                  <p></p>
                  <p>We prove that Wasserstein GANs with infinitely wide generators have no spurious stationary points in the optimization landscape.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <img src="assets/img/memorization.png" alt="ICML Workshop" width="220" style="border-style: none">
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/forum?id=shciCbSk9h">
                    <papertitle>Diffusion Probabilistic Models Generalize when They Fail to Memorize</papertitle>
                  </a>
                  <br>
                  TaeHo Yoon, Joo Young Choi, <strong>Sehyun Kwon</strong>, Ernest K. Ryu
                  <br>
                  <em>ICML 2023 Workshop on Structured Probabilistic Inference & Generative Modeling</em>, 2023
                  <br>
                  <a href="https://openreview.net/forum?id=shciCbSk9h">paper</a>
                  <p></p>
                  <p>We study the memorization and generalization properties of diffusion probabilistic models.</p>
                </td>
              </tr>

            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:40px 20px 10px 20px;width:100%;vertical-align:middle">
                  <heading>Fellowships and Awards</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                  <p>
                    <strong>Youlchon AI Star Fellowship</strong>, 2024
                  </p>
                  <p>
                    <strong>Outstanding TA Award</strong> for the Mathematical Foundations of Deep Neural Networks course, Seoul National University, 2022
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
    </tbody>
  </table>
</body>
</html>
